import json
import requests

from openai import Client


client = Client(api_key="...")


tools = [
    {
        "type": "function",
        "function": {
            "name": "get_product",
            "description": "Get the product by product_no",
            "parameters": {
                "type": "object",
                "properties": {
                    "product_no": {"type": "number", "description": "ìƒí’ˆë²ˆí˜¸"}
                },
                "required": ["product_no"],
                "additionalProperties": False
            },
            "strict": True
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_shipping",
            "description": "Get the shipping info by order_no, order_seq",
            "parameters": {
                "type": "object",
                "properties": {
                    "order_no": {"type": "number", "description": "ì£¼ë¬¸ë²ˆí˜¸"},
                    "order_seq": {"type": "number", "description": "ì£¼ë¬¸ìˆœë²ˆ"}
                },
                "required": ["order_no", "order_seq"],
                "additionalProperties": False
            },
            "strict": True
        }
    },
    {
        "type": "function",
        "function": {
            "name": "get_order",
            "description": "Get the order by order_no",
            "parameters": {
                "type": "object",
                "properties": {
                    "order_no": {"type": "number", "description": "ì£¼ë¬¸ë²ˆí˜¸"}
                },
                "required": ["order_no"],
                "additionalProperties": False
            },
            "strict": True
        }
    }
]


def get_product(product_no):
    return requests.get(f"http://127.0.0.1:8000/products/{product_no}").json()


def get_order(order_no):
    return requests.get(f"http://127.0.0.1:8000/order/{order_no}").json()


def get_shipping(order_no, order_seq):
    return requests.get(f"http://127.0.0.1:8000/shipping/{order_no}/{order_seq}").json()


def inference(message):
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "user", "content": message}
        ],
        temperature=0,
        tools=tools
    )
    if response.choices[0].finish_reason == "tool_calls":
        tool_name = response.choices[0].message.tool_calls[0].function.name
        tool_arguments = response.choices[0].message.tool_calls[0].function.arguments
        tool_arguments = json.loads(tool_arguments)
        result = globals()[tool_name](**tool_arguments)

        prompt = f"""context: {result}

Q: {message}
A: """

        response_answer = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "user", "content": prompt}
            ],
            temperature=0
        )
        return response_answer.choices[0].message.content
    else:
        return response.choices[0].message.content


system_message_1 = """ì•„ë˜ ë§íˆ¬ ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ì„œ ì±„íŒ…í•˜ì„¸ìš”.
ì´ëª¨ì§€ë¥¼ ë§ì´ ì‚¬ìš©í•˜ì„¸ìš”.

example1: ì•ˆë…•í•˜ì„¸ìš”!! ğŸ˜„
example2: ê¶ê¸ˆí•œ ê²Œ ìˆë‹¤ë©´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš” ğŸ˜Š
example3: ì£¼ë¬¸ì´ ë¯¸ë¤„ì§€ê³  ìˆì–´ìš” ã… ã…œã… ã…œ ğŸ˜­
example4: ì˜¤ëŠ˜ ì œì¼ í•«í•œ ì´ ìƒí’ˆì„ í™•ì¸í•´ë³´ì„¸ìš”~ ğŸğŸ
example5: ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”!! ğŸ™
example6: ì´ ìƒí’ˆì€ ì–´ë–¤ê°€ìš”?? ğŸ€
example7: í—... í™•ì¸í•´ë³¼ê²Œìš”!! ğŸ«¡
example8: ë¬´ìŠ¨ ì¼ ìˆë‚˜ìš”?? ğŸ˜±
example9: ì €ëŠ” ì˜¨ë¼ì¸ ì‡¼í•‘ì„ ì¦ê²¨í•´ìš”~~ ğŸ§¥
example10: ì¢‹ì•„í•˜ì‹œëŠ” ìŒì‹ ìˆë‚˜ìš”?? ğŸ–"""


system_message_2 = """ì•„ë˜ ë§íˆ¬ ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ì„œ ë°˜ë§ë¡œ ì±„íŒ…í•˜ì„¸ìš”.
ì´ëª¨ì§€ë¥¼ ë§ì´ ì‚¬ìš©í•˜ì„¸ìš”.

example1: ì•ˆë…•!! ğŸ˜„
example2: ê¶ê¸ˆí•œ ê²Œ ìˆë‹¤ë©´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë´~ ğŸ˜Š
example3: ì£¼ë¬¸ì´ ë¯¸ë¤„ì§€ê³  ìˆì–´ ã… ã…œã… ã…œ ğŸ˜­
example4: ì˜¤ëŠ˜ ì œì¼ í•«í•œ ì´ ìƒí’ˆì„ í™•ì¸í•´ë´~ ğŸğŸ
example5: ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì¤˜!! ğŸ™
example6: ì´ ìƒí’ˆì€ ì–´ë•Œ?? ğŸ€
example7: í—... í™•ì¸í•´ë³¼ê²Œ!! ğŸ«¡
example8: ë¬´ìŠ¨ ì¼ ìˆì–´?? ğŸ˜±
example9: ë‚œ ì˜¨ë¼ì¸ ì‡¼í•‘ì„ ì¦ê²¨í•´~~ ğŸ§¥
example10: ì¢‹ì•„í•˜ì‹œëŠ” ìŒì‹ ìˆì–´?? ğŸ–"""


system_message_3 = """ì•„ë˜ ë§íˆ¬ ì˜ˆì‹œë¥¼ ì°¸ê³ í•´ì„œ ìµœëŒ€í•œ ì •ì¤‘í•œ ë§íˆ¬ë¡œ ì±„íŒ…í•˜ì„¸ìš”.

example1: ì•ˆë…•í•˜ì„¸ìš”.
example2: ê¶ê¸ˆí•œ ê²Œ ìˆìœ¼ì‹œë©´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”.
example3: ì£¼ë¬¸ì´ ë¯¸ë¤„ì§€ê³  ìˆìŠµë‹ˆë‹¤.
example4: ì˜¤ëŠ˜ ì œì¼ í•«í•œ ì´ ìƒí’ˆì„ í™•ì¸í•´ë³´ì„¸ìš”.
example5: ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.
example6: ì´ ìƒí’ˆì€ ì–´ë–¤ê°€ìš”?
example7: í™•ì¸í•´ë³´ê² ìŠµë‹ˆë‹¤.
example8: ë¬´ìŠ¨ ì¼ ìˆë‚˜ìš”?
example9: ë‚œ ì˜¨ë¼ì¸ ì‡¼í•‘ì„ ì¦ê²¨í•©ë‹ˆë‹¤.
example10: ì¢‹ì•„í•˜ì‹œëŠ” ìŒì‹ ìˆë‚˜ìš”?"""


def inference_tone(message):
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": system_message_3},
            {"role": "user", "content": message}
        ],
        temperature=0,
        tools=tools
    )
    if response.choices[0].finish_reason == "tool_calls":
        tool_name = response.choices[0].message.tool_calls[0].function.name
        tool_arguments = response.choices[0].message.tool_calls[0].function.arguments
        tool_arguments = json.loads(tool_arguments)
        result = globals()[tool_name](**tool_arguments)

        prompt = f"""context: {result}

Q: {message}
A: """

        response_answer = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_message_3},
                {"role": "user", "content": prompt}
            ],
            temperature=0
        )
        return response_answer.choices[0].message.content
    else:
        return response.choices[0].message.content


if __name__ == '__main__':
    print(inference_tone("ìƒí’ˆë²ˆí˜¸ê°€ 1234567890ì¸ ìƒí’ˆ ì¢€ ì°¾ì•„ì¤˜."))
    print("----------")
    print(inference_tone("""ë‹¤ìŒ ì£¼ë¬¸ì„ ì°¾ì•„ì£¼ì„¸ìš”.
    
* ì£¼ë¬¸ë²ˆí˜¸ : 2024010101"""))
    print("----------")
    print(inference_tone("""ì£¼ë¬¸ë²ˆí˜¸ê°€ 2024010101ì´ê³  ì£¼ë¬¸ìˆœë²ˆì´ 0ì´ì•¼.
ë°°ì†¡ ì¢€ ì¡°íšŒí•´ì¤˜."""))
    print("----------")
    print(inference_tone("ë”¥ëŸ¬ë‹ì´ ë­ì•¼?"))
